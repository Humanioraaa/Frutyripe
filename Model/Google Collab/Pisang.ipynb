{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FrPbF9MfmZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0669fa3f-9eaa-4ec2-dd9f-acb56dd11514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "metadata": {
        "id": "Nyr1uX7ZdByn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inceptionv3 = 'https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "#urllib.request.urlretrieve(inceptionv3, 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "local_weights_file = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(weights=local_weights_file,\n",
        "                                    input_shape=(150, 150, 3),\n",
        "                                    include_top=False)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_layer = pre_trained_model.output"
      ],
      "metadata": {
        "id": "W1siS0xz09VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/datasets/Train' #os.path.join(dataset, \"Train\")\n",
        "validation_dir = '/content/drive/MyDrive/datasets/Test' #os.path.join(dataset, \"Test\")\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=128,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(validation_dir,\n",
        "                                                target_size=(150, 150),\n",
        "                                                batch_size=32,\n",
        "                                                class_mode='binary')\n",
        "\n",
        "x = last_layer\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF6DA38LdbgH",
        "outputId": "a0850870-d49a-447d-818e-4d5d1eba8fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1420 images belonging to 2 classes.\n",
            "Found 720 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def solution_A3():\n",
        "  model.fit(train_generator,\n",
        "          epochs=20,\n",
        "          steps_per_epoch=8,\n",
        "          verbose=1,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=8)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cKfrOn9pd8eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  model = solution_A3()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnZYnrYleDAQ",
        "outputId": "2bf416bd-f7ad-421d-96a7-82cc83ffd29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 124s 16s/step - loss: 1.9890 - acc: 0.7070 - val_loss: 0.2086 - val_acc: 0.9336\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 49s 7s/step - loss: 0.1517 - acc: 0.9537 - val_loss: 0.0982 - val_acc: 0.9648\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.0670 - acc: 0.9868 - val_loss: 0.0702 - val_acc: 0.9844\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.0668 - acc: 0.9824 - val_loss: 0.0612 - val_acc: 0.9883\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 22s 3s/step - loss: 0.0486 - acc: 0.9780 - val_loss: 0.0400 - val_acc: 0.9922\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 19s 3s/step - loss: 0.0213 - acc: 0.9971 - val_loss: 0.0738 - val_acc: 0.9766\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 22s 3s/step - loss: 0.1602 - acc: 0.9383 - val_loss: 0.0197 - val_acc: 0.9922\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0102 - acc: 0.9990 - val_loss: 0.0216 - val_acc: 0.9883\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.0205 - val_acc: 0.9922\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 14s 2s/step - loss: 0.0142 - acc: 0.9967 - val_loss: 0.0058 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 14s 2s/step - loss: 0.0169 - acc: 0.9934 - val_loss: 0.0157 - val_acc: 0.9961\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.0556 - acc: 0.9769 - val_loss: 0.5203 - val_acc: 0.8320\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 15s 2s/step - loss: 0.0967 - acc: 0.9670 - val_loss: 0.0117 - val_acc: 0.9961\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.0054 - acc: 0.9989 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 15s 2s/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 14s 2s/step - loss: 0.0041 - acc: 0.9978 - val_loss: 0.0052 - val_acc: 0.9961\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 14s 2s/step - loss: 0.0048 - acc: 0.9989 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.0100 - acc: 0.9961 - val_loss: 0.0104 - val_acc: 0.9922\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 15s 2s/step - loss: 0.0141 - acc: 0.9945 - val_loss: 0.0102 - val_acc: 0.9922\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 14s 2s/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0020 - val_acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = 'images.jpg'  # Ganti dengan path gambar yang diunggah\n",
        "img = image.load_img(img_path, target_size=(150, 150))  # Sesuaikan dengan ukuran input model Anda\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Sesuaikan normalisasi jika diperlukan\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "if predictions[0][0] > 0.5:\n",
        "    print(\"semi-ripe banana\")\n",
        "else:\n",
        "    print(\"full-ripe banana\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVTRIEFVjhFv",
        "outputId": "1ba2b3f0-b1b6-4db2-fe82-a0aa290d45c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "full-ripe banana\n"
          ]
        }
      ]
    }
  ]
}